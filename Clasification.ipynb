{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0e1b62e350e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHistory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras_metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras_metrics'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Dropout,Conv1D,MaxPooling1D,initializers,Input\n",
    "from keras.models import Model\n",
    "from keras import optimizers,regularizers\n",
    "from keras.callbacks import History,EarlyStopping\n",
    "from keras.optimizers import SGD\n",
    "import keras_metrics\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.loadtxt('newdata.txt')\n",
    "Y=np.loadtxt('newlabels.txt')\n",
    "Y=Y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "X,Y= shuffle(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_values = np.max(Y) + 1\n",
    "newY=np.eye(n_values)[Y]\n",
    "print(newY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=int(X.shape[0]*0.80)\n",
    "length=X.shape[0]\n",
    "X_train=X[0:n,:]\n",
    "X_test=X[n:,:]\n",
    "\n",
    "Y_train=Y[0:n]\n",
    "Y_test=Y[n:]\n",
    "\n",
    "newY_train=newY[0:n]\n",
    "newY_test=newY[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "print(newY_train.shape)\n",
    "print(newY_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "accuracy=[]\n",
    "f1=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "\n",
    "f1_class=np.empty((0,7))\n",
    "precision_class=np.empty((0,7))\n",
    "recall_class=np.empty((0,7))\n",
    "for train, test in kfold.split(X_train, newY_train,Y_train):\n",
    "  # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=79, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(7, activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(X_train[train], newY_train[train], epochs=10, batch_size=10, verbose=2)\n",
    "    y_pred=model.predict(X_train[test])\n",
    "#     print(y_pred)\n",
    "    predict_class = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    #f1 values\n",
    "    f1_value=metrics.f1_score(predict_class,Y_train[test],average='macro')\n",
    "    f1_class_value=metrics.f1_score(predict_class,Y_train[test],average=None).reshape(1, -1)\n",
    "    \n",
    "    #precision values\n",
    "    precision_value=metrics.precision_score(predict_class,Y_train[test],average='macro')\n",
    "    precision_class_value=metrics.precision_score(predict_class,Y_train[test],average=None).reshape(1, -1)\n",
    "    \n",
    "    #recall values\n",
    "    recall_value=metrics.recall_score(predict_class,Y_train[test],average='macro')\n",
    "    recall_class_value=metrics.recall_score(predict_class,Y_train[test],average=None).reshape(1, -1)\n",
    "    \n",
    "    scores = model.evaluate(X_train[test], newY_train[test], verbose=0)\n",
    "    accuracy.append(scores[1])\n",
    "    \n",
    "    f1.append(f1_value)\n",
    "    precision.append(precision_value)\n",
    "    recall.append(recall_value)\n",
    "    \n",
    "    f1_class=np.concatenate((f1_class,f1_class_value),axis=0)\n",
    "    print(f1_class)\n",
    "    precision_class=np.concatenate((precision_class,precision_class_value),axis=0)\n",
    "    recall_class=np.concatenate((recall_class,recall_class_value),axis=0)\n",
    "    \n",
    "average_f1=f1_class.mean(axis=0)\n",
    "average_precision=precision_class.mean(axis=0)\n",
    "average_recall=recall_class.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For training:\")\n",
    "print(\"Accuracy is :\"+ str(np.mean(accuracy)))\n",
    "print(\"F1 is :\"+ str(np.mean(f1)))\n",
    "print(\"Precision is: \"+str(np.mean(precision)))\n",
    "print(\"Recall is: \"+str(np.mean(recall)))\n",
    "print(\"\\n\")\n",
    "print(\"Average F1 for all the classes is:\" +str(average_f1))\n",
    "print(\"Average F1 for all the classes is:\" +str(average_precision))\n",
    "print(\"Average F1 for all the classes is:\" +str(average_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on the other models, we will compare the score against the other models\n",
    "#and then see how well the model will generalise based on the test scores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
