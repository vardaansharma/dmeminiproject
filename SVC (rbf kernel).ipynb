{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2464, 79)\n",
      "(2464, 1)\n"
     ]
    }
   ],
   "source": [
    "#loading data\n",
    "\n",
    "X = pd.read_csv('newdata.txt',header=None,sep=\" \")\n",
    "Y = pd.read_csv('newlabels.txt',header=None, sep=\" \")\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2095</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "930   0.0\n",
       "2095  0.0\n",
       "816   0.0\n",
       "2375  0.0\n",
       "812   6.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffling data\n",
    "\n",
    "idx = np.random.permutation(X.index)\n",
    "X = X.reindex(idx)\n",
    "Y = Y.reindex(idx)\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliiting training and  testing data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\homoe\\Miniconda3\\envs\\dme\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\homoe\\Miniconda3\\envs\\dme\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\homoe\\Miniconda3\\envs\\dme\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\homoe\\Miniconda3\\envs\\dme\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\homoe\\Miniconda3\\envs\\dme\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\homoe\\Miniconda3\\envs\\dme\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\homoe\\Miniconda3\\envs\\dme\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\homoe\\Miniconda3\\envs\\dme\\lib\\site-packages\\sklearn\\metrics\\classification.py:1145: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "C:\\Users\\homoe\\Miniconda3\\envs\\dme\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "accuracy=[]\n",
    "f1=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "\n",
    "f1_class=np.empty((0,7))\n",
    "precision_class=np.empty((0,7))\n",
    "recall_class=np.empty((0,7))\n",
    "# X=np.loadtxt('newdata.txt')\n",
    "# Y=np.loadtxt('newlabels.txt')\n",
    "# Y=Y.astype(int)\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = Y.iloc[train_index], Y.iloc[test_index]\n",
    "    \n",
    "    \n",
    "    smote_tomek = SMOTETomek(random_state=0)\n",
    "    X_under, y_under=smote_tomek.fit_resample(X_train, y_train) #sampling on the trainng data only\n",
    "    X_under,y_under= shuffle(X_under,y_under)\n",
    "    \n",
    "    \n",
    "    clf = SVC(kernel='rbf',gamma='scale',decision_function_shape='ovo')\n",
    "    clf.fit(X_under, y_under)\n",
    "    predict_class = clf.predict(X_test)\n",
    "    \n",
    "       #f1 values\n",
    "    f1_value=metrics.f1_score(predict_class,y_test,average='macro')\n",
    "    f1_class_value=metrics.f1_score(predict_class,y_test,average=None).reshape(1, -1)\n",
    "    \n",
    "    #precision values\n",
    "    precision_value=metrics.precision_score(predict_class,y_test,average='macro')\n",
    "    precision_class_value=metrics.precision_score(predict_class,y_test,average=None).reshape(1, -1)\n",
    "    \n",
    "    #recall values\n",
    "    recall_value=metrics.recall_score(predict_class,y_test,average='macro')\n",
    "    recall_class_value=metrics.recall_score(predict_class,y_test,average=None).reshape(1, -1)\n",
    "    \n",
    "#     scores = model.evaluate(X_train[test], newY_train[test], verbose=0)\n",
    "#     accuracy.append(scores[1])\n",
    "    \n",
    "    f1.append(f1_value)\n",
    "    precision.append(precision_value)\n",
    "    recall.append(recall_value)\n",
    "    \n",
    "    f1_class=np.concatenate((f1_class,f1_class_value),axis=0)\n",
    "#     print(f1_class)\n",
    "    precision_class=np.concatenate((precision_class,precision_class_value),axis=0)\n",
    "    recall_class=np.concatenate((recall_class,recall_class_value),axis=0)\n",
    "    \n",
    "average_f1=f1_class.mean(axis=0)\n",
    "average_precision=precision_class.mean(axis=0)\n",
    "average_recall=recall_class.mean(axis=0)\n",
    "#     f1.append(metrics.f1_score(predictions,y_test,average='macro'))\n",
    "#     prs.append(metrics.precision_score(predictions,y_test,average='macro'))\n",
    "#     recall.append\n",
    "#     print(clf)\n",
    "#     print(y_test)\n",
    "#     print(clf.predict(X_test))\n",
    "#     print(clf.decision_function(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training:\n",
      "Accuracy is :nan\n",
      "F1 is :0.6767296527270961\n",
      "Precision is: 0.6616292517006803\n",
      "Recall is: 0.7083349915217769\n",
      "\n",
      "\n",
      "Average F1 for all the classes is:[0.98398792 0.29428571 0.75384615 0.94828449 0.86336996 0.89333333\n",
      " 0.        ]\n",
      "Average F1 for all the classes is:[0.9875     0.3        0.70666667 0.97533333 0.82857143 0.83333333\n",
      " 0.        ]\n",
      "Average F1 for all the classes is:[0.98052701 0.3        0.84285714 0.92543697 0.90952381 1.\n",
      " 0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\homoe\\Miniconda3\\envs\\dme\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\homoe\\Miniconda3\\envs\\dme\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "print(\"For training:\")\n",
    "print(\"Accuracy is :\"+ str(np.mean(accuracy)))\n",
    "print(\"F1 is :\"+ str(np.mean(f1)))\n",
    "print(\"Precision is: \"+str(np.mean(precision)))\n",
    "print(\"Recall is: \"+str(np.mean(recall)))\n",
    "print(\"\\n\")\n",
    "print(\"Average F1 for all the classes is:\" +str(average_f1))\n",
    "print(\"Average F1 for all the classes is:\" +str(average_precision))\n",
    "print(\"Average F1 for all the classes is:\" +str(average_recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
